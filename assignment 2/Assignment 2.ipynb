{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sq\n",
    "from collections import defaultdict\n",
    "from nltk import ngrams\n",
    "import tqdm\n",
    "import glob, os\n",
    "import shelve\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None hi\n",
      "None hi i\n",
      "hi i am\n",
      "i am kapil\n",
      "am kapil None\n",
      "kapil None None\n"
     ]
    }
   ],
   "source": [
    "sentence='hi i am kapil'.split()\n",
    "for i,j,k in ngrams(sentence,n=3 ,pad_right=True, pad_left=True):\n",
    "    print(i,j,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The method\n",
    "Here we describe the method for trigram model. Similar method is used for 4gram model\n",
    "- The frequencies of bigram and trigram are stored in a database. We didnt use dictionary since it had to be loaded into memory and it was slowing down the pc. Instead, by using database we are storing the data onto disk rather than memory.\n",
    "- Training on 2000 documents seemed to be sufficient. Also training on whole data led to very large database size.\n",
    "- Then we compute the conditional probabilities.\n",
    "- Finally we generate sentences.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intitializing the databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgram=sq.connect('fourgram_model')\n",
    "trigram=sq.connect('trigram_model')\n",
    "bigram=sq.connect('bigrams')\n",
    "f=fourgram.cursor()\n",
    "t=trigram.cursor()\n",
    "b=bigram.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    b.execute('DROP TABLE bigrams')\n",
    "except:\n",
    "    b.execute('''CREATE TABLE bigrams\n",
    "             (w1 text, w2 text, num FLOAT DEFAULT 0,PRIMARY KEY(w1,w2))''')\n",
    "try:\n",
    "    t.execute('DROP TABLE trigrams')\n",
    "except:\n",
    "    t.execute('''CREATE TABLE trigrams\n",
    "             (w1 text, w2 text, w3 text, num FLOAT DEFAULT 0, prob FLOAT,PRIMARY KEY(w1,w2,w3))''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f.execute('DROP TABLE fourgrams')\n",
    "except:\n",
    "    f.execute('''CREATE TABLE fourgrams\n",
    "             (w1 text, w2 text, w3 text, w4 text, num FLOAT DEFAULT 0, prob FLOAT,PRIMARY KEY(w1,w2,w3,w4))''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data='../assignment 1/processed_text'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we store all the frequencies of trigrams and bigrams into the databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                         | 1999/153862 [05:37<7:07:41,  5.92it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "for fname in tqdm.tqdm(os.listdir(f'{data}//')):\n",
    "    i+=1\n",
    "    if i==2000:\n",
    "        break\n",
    "    with open(f'{data}//{fname}') as f:\n",
    "        text=f.read()\n",
    "    sentences=text.split('.')\n",
    "    for s in sentences:\n",
    "        words=s.split()\n",
    "        if len(words)<3:\n",
    "            continue\n",
    "        for w1,w2,w3 in ngrams(words,n=3,pad_right=True, pad_left=True,left_pad_symbol='\\x00', right_pad_symbol='\\x00'):\n",
    "            if w1==w2==w3:\n",
    "                continue\n",
    "            t.execute('INSERT OR IGNORE INTO trigrams (w1, w2,w3) VALUES (?,?,?)',(w1,w2,w3))\n",
    "            t.execute('UPDATE trigrams SET num = num+1 WHERE (w1,w2,w3) IS (?,?,?)',(w1,w2,w3))\n",
    "            b.execute('INSERT OR IGNORE INTO bigrams (w1, w2) VALUES (?,?)',(w1,w2))\n",
    "            b.execute('UPDATE bigrams SET num = num+1 WHERE (w1,w2) IS (?,?)',(w1,w2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1711842it [01:02, 27375.70it/s]\n"
     ]
    }
   ],
   "source": [
    "trigram.commit()\n",
    "bigram.commit()\n",
    "t2=trigram.cursor()\n",
    "b.execute('SELECT * FROM bigrams') \n",
    "for row in tqdm.tqdm(b):\n",
    "    t2.execute('UPDATE trigrams SET prob=num/? where (w1,w2) IS (?,?)',(row[2],row[0],row[1]))\n",
    "trigram.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets generate sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence generated with most occuring starting word is --- the copyright holder for this preprint this version posted may  ---\n",
      "\n",
      "Some random sentences generated using one among first 3 predictions are\n",
      "\n",
      "this may be a promising therapeutic tools are required to determine which of them were located at residues and which were used for all of the covid outbreak \n",
      "\n",
      "we found the mean time between onset and hospital admission \n",
      "\n",
      "we have a financial incentive for practices risp and a significant increase p and higher than in those countries that are more likely to report the average of all the above two guidelines \n",
      "\n",
      "in this paper we introduce a new approach provided private multisite fmri analysis through numerical results for sarscov and sarscov spike protein s and s the summation of binding of viral infection \n"
     ]
    }
   ],
   "source": [
    "t=trigram.cursor()\n",
    "ans=''\n",
    "\n",
    "for i in range(5):\n",
    "    curr=['\\x00','\\x00']\n",
    "    ans=''\n",
    "    while True:\n",
    "        res=list(t.execute('SELECT prob,w3 FROM trigrams WHERE (w1,w2) IS (?,?) ',curr))\n",
    "        res.sort()\n",
    "        if i==0:\n",
    "            last=res[-1][1]\n",
    "        else:\n",
    "            last=res[-min(random.randint(1,4),len(res))][1]\n",
    "        if last=='\\x00':\n",
    "            break\n",
    "        ans+=last+' '\n",
    "        curr.pop(0)\n",
    "        curr.append(last)\n",
    "    if i==0:\n",
    "        print(\"Sentence generated with most occuring starting word is ---\",ans,'---')\n",
    "        print('')\n",
    "    else:\n",
    "        if i==1:\n",
    "            print(\"Some random sentences generated using one among first 3 predictions are\")\n",
    "        print('')\n",
    "        print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the frequencies of four gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                         | 1999/153862 [04:02<5:07:33,  8.23it/s]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for fname in tqdm.tqdm(os.listdir(f'{data}//')):\n",
    "    i+=1\n",
    "    if i==2000:\n",
    "        break\n",
    "    with open(f'{data}//{fname}') as fi:\n",
    "        text=fi.read()\n",
    "    sentences=text.split('.')\n",
    "    for s in sentences:\n",
    "        words=s.split()\n",
    "        if len(words)<3:\n",
    "            continue\n",
    "        for w1,w2,w3,w4 in ngrams(words,n=4,pad_right=True, pad_left=True,left_pad_symbol='\\x00', right_pad_symbol='\\x00'):\n",
    "            if (w1==w2 or w2==w3 or w3==w4) and (w1!='\\x00' and w2!='\\x00' and w3!='\\x00' and w4!='\\x00'):\n",
    "                continue\n",
    "            f.execute('INSERT OR IGNORE INTO fourgrams (w1, w2,w3,w4) VALUES (?,?,?,?)',(w1,w2,w3,w4))\n",
    "            f.execute('UPDATE fourgrams SET num = num+1 WHERE (w1,w2,w3,w4) IS (?,?,?,?)',(w1,w2,w3,w4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting into probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4366468it [01:54, 38130.64it/s]\n"
     ]
    }
   ],
   "source": [
    "fourgram.commit()\n",
    "f2=fourgram.cursor()\n",
    "t.execute('SELECT * FROM trigrams') \n",
    "for row in tqdm.tqdm(t):\n",
    "    if row[0]==row[1]==row[2]=='\\x00':\n",
    "        f2.execute('UPDATE fourgrams SET prob=num/? where (w1,w2,w3) IS (?,?,?)',(1,row[0],row[1],row[2]))\n",
    "    else:\n",
    "        f2.execute('UPDATE fourgrams SET prob=num/? where (w1,w2,w3) IS (?,?,?)',(row[-2],row[0],row[1],row[2]))\n",
    "f2.execute('UPDATE fourgrams SET prob=num/? where (w1,w2,w3) IS (?,?,?)',(1,'\\x00','\\x00','\\x00'))\n",
    "fourgram.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets Generate sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence generated with most occuring starting word is --- the copyright holder for this preprint this version posted may  ---\n",
      "\n",
      "Some random sentences generated using one among first 3 predictions are\n",
      "\n",
      "in the first year of life for many american families board of governors \n",
      "\n",
      "the copyright for prismap including checklist is held by one individual is now reduced by the proportion of publichealth expenditure and fiscal expenditure is shown in figure the number of cases \n",
      "\n",
      "we also found evidence for recombination deduced from the sequence read archive sra database accession no \n",
      "\n",
      "the first step is that each view is now a critical function and that the k antagonist mr indicating the drug acted like a u agonist in this situation with the focus of this paper \n"
     ]
    }
   ],
   "source": [
    "f=fourgram.cursor()\n",
    "ans=''\n",
    "for i in range(5):\n",
    "    curr=['\\x00','\\x00','\\x00']\n",
    "    ans=''\n",
    "    while True:\n",
    "        res=list(f.execute('SELECT prob,w4 FROM fourgrams WHERE (w1,w2,w3) IS (?,?,?) ',curr))\n",
    "        res.sort()\n",
    "        if i==0:\n",
    "            last=res[-1][1]\n",
    "        else:\n",
    "            last=res[-min(random.randint(1,4),len(res))][1]\n",
    "        if last=='\\x00':\n",
    "            break\n",
    "        ans+=last+' '\n",
    "        curr.pop(0)\n",
    "        curr.append(last)\n",
    "    if i==0:\n",
    "        print(\"Sentence generated with most occuring starting word is ---\",ans,'---')\n",
    "        print('')\n",
    "    else:\n",
    "        if i==1:\n",
    "            print(\"Some random sentences generated using one among first 3 predictions are\")\n",
    "        print('')\n",
    "        print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "- The senetences generated using the highest probability words were same for both trigram and 4gram model\n",
    "- Looking at the senetences generated by using random element from top 3 highest probability words, it seems 4gram model performs better. This might be bcoz 4gram performs 'lookahead' better than trigrams. Also the crucial thing is that the dataset for 4gram was large enough. Otherwise, it would simple have overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Answers to other questions\n",
    "\n",
    "##### Efficient ways to handle the large set of parameters\n",
    "- We used database instead of dictionary for this purpose. Hence the data was loaded onto disk rather than memory and could be efficiently retrieved when generating sentences.\n",
    "\n",
    "##### Is it possible to run any portion of the code in parallel? If yes, which part of the code? If no, why?\n",
    "- We can use several threads to process multiple files to generate the frequencies of ngrams in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
